# Queuing Discipline

- __First-In-First-Out (FIFO)__
    + Do not discriminate between traffic sources (one queue for all).
- __[Fair Queuing (FQ)](#fair-queuing-fq)__
    + Explicitly segregates traffic based on flows (by label)
    + Ensures no flow captures more than its share of capacity
    + Variation: weighted fair queuing (WFQ)

# Fair Queuing (FQ)
Quote from [Wikipidia](https://en.wikipedia.org/wiki/Fair_queuing):
> __Fair queuing__ is a family of [scheduling
> algorithms](https://en.wikipedia.org/wiki/Scheduling_algorithm) used in some
> [process](https://en.wikipedia.org/wiki/Process_scheduler) and [network
> schedulers](https://en.wikipedia.org/wiki/Network_scheduler). The concept
> implies a separate data packet queue (or job queue) for each [traffic
> flow](https://en.wikipedia.org/wiki/Traffic_flow_(computer_networking)) (or
> for each program process) as opposed to the traditional approach with one
> [FIFO](https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics)) queue
> for all packet flows (or for all process jobs). The purpose is to achieve
> [fairness](https://en.wikipedia.org/wiki/Fairness_measure) when a limited
> resource is shared, for example to avoid that flows with large packets (or
> processes that generate small jobs) achieve more throughput (or CPU time)
> than other flows (or processes).

In FQ, there are two systems:

- The real system: This is the real router with a real output link and the real flows arriving into the router
- [The Fake system](#the-fake-system)
    + It does not exist (only used as reference by real system).
    + It has the same output link capacity as the real system.
    + It has the same input flows (with the same packets) as the real system.
    + However, it is a ___bit-by-bit___ server (actually, a __fluid server__),
      not a packet server. More formally, it serves all queued flows at the
      same time.

## The Fake System
In short, the fake system is a __bit-by-bit round-robin__ server.

Suppose a fake clock ticks each time a bit is transmitted from every active
flow (i.e., after each round), (a counter rather than a real clock). Let

- ![](http://latex.codecogs.com/gif.latex?L_{f,i}) denote the length of
  ![](http://latex.codecogs.com/gif.latex?(f,i)), i.e., _i_-th packet of flow
  ![](http://latex.codecogs.com/gif.latex?f);
- ![](http://latex.codecogs.com/gif.latex?S_{f,i}) denote the fake time when
  start to transmit packet _i_ in the fake system;
- ![](http://latex.codecogs.com/gif.latex?F_{f,i}) denote the fake time when
  finish transmitting packet _i_ in the fake system (regardless of other
  flows).

Then, ![](http://latex.codecogs.com/gif.latex?F_{f,i}=S_{f,i}+L_{f,i}).

- If when ![](http://latex.codecogs.com/gif.latex?f_i) arrives, server has not
  finished packet ![](http://latex.codecogs.com/gif.latex?f_{i-1}) from flow
  ![](http://latex.codecogs.com/gif.latex?f), then start transmit packet
  ![](http://latex.codecogs.com/gif.latex?f_i) immediately after last bit of
  ![](http://latex.codecogs.com/gif.latex?f_{i-1}), i.e.,
  ![](http://latex.codecogs.com/gif.latex?S_{f,i}=F_{f,i-1}).
- If no current packets queued for this flow, then start transmitting packet
  ![](http://latex.codecogs.com/gif.latex?f_i) when it arrives, i.e.,
  ![](http://latex.codecogs.com/gif.latex?S_{f,i}=V_{f,i}), where
  ![](http://latex.codecogs.com/gif.latex?V_{f,i}) is the fake time when the
  packet arrives.

Thus,
![](http://latex.codecogs.com/gif.latex?F_{f,i}=S_{f,i}+L_{f,i}=\max\(F_{f,i-1},V_{f,i}\)+L_{f,i} )
._

## Calculate *V*
___V___ is not real time. It grows depending on the number of backlogged flows
(flows whose queue is not empty) in the fake server:

- Output channel rate is __constant__
- Tick after transmitting one bit of each flow
- If more flows, then it takes more time to transmit one bit of each flow (the
  round takes more time).

Hence, the number of queued flows dictates how fast (with respect to real-time)
___V___ grows.

Packets are sent out according to which one would exit the fake server first.
(try to mimic the fake server)

__Note that:__ we don’t know the real-time of when a packet exits the fake
server, but we know the fake time. Thus, if
![](http://latex.codecogs.com/gif.latex?F_{f,i}>F_{g,j}) we know `(g,j)` exits
the fake server before `(f,i)`, and thus is given higher priority

## Limitation

We want to emulate the behavior of the bit-by-bit server as much as possible.
So, we want each packet to exit from the real server __no later than__ it exits
from the bit-by-bit server. However, nothing's perfect: we can’t preempt
current packet, so exit time may be greater (but only by one packet!)

# TCP Congestion Control

Basic idea:

- Assumes best-effort network (FIFO or FQ routers)
- Each source determines network capacity for itself
- Uses implicit feedback
- ACKs pace transmission (_self-clocking_)

But there are some challenges:

- How to determine the available capacity in the first place?
- How to adjust to changes in the available capacity?

## Self-clocking or ACK Clock

To simplify argument, we made following assumptions:

- We generate an ACK for every data message received.
- The sender has always data to send.

Under normal behavior (i.e., no loss) the window is “closed” i.e., the sender
cannot send until a new ACK arrives. It is easy to see that __Self-clocking
systems__ tend to be very stable under a wide range of bandwidths and delays.
The principal issue with self-clocking systems is __getting them started__.

Considering throughput, theoretically, If the window is _W_, and if the base
round-trip delay is _baseRTT_ (without queuing delay), the optimal window size
should be: `Wopt = optimum window = baseRTT * Bandwidth`

TCP does NOT know what _baseRTT_ is (the network does not tell it) nor the
bandwidth!

So, it CAN’t compute `Wopt`!

## Additive increase/multiplicative decrease (AIMD)

There are two TCP congestion states.
- Congestion _avoidance_: Normal operation, no congestion has been detected.
- Congestion control.

Let the sender's window now defined as: `CongestionWindow`

    (LastByteSent - LastByteAcked) <= CongestionWindow

An intuitive idea is:

- increase `CongestionWindow` when congestion goes down
- decrease `CongestionWindow` when congestion goes up

We consider congestion exists when a timeout occurs. The AIMD algorithm run as
follow:

- Increase `CongestionWindow` by 1 packet every RTT,
- Cut `CongestionWindow` in half whenever a timeout occurs.

However, initially, you don’t know the network capacity. What then should be
the initial value of `CongestionWindow`?
- If `CongestionWindow` is too small, we waste bandwidth, since it takes a long
  time for `CongestionWindow` to grow using AIMD.
- If `CongestionWindow` is too big we cause congestion.
- Furthermore, Dumping `CongestionWindow`bytes in the network, at once, even if
  _W_ is the right value, may cause congestion.

Hence, we introduce slow start.

## Slow Start

Basic idea:
- Begin with `CongestionWindow` = 1 packet
- Double `CongestionWindow` each RTT (_increment by 1 packet for **each ACK**_)
- After sometime, swtich back to linearly increment (_increment by 1 packet for
  **each RTT**_)

Slow start enables __Exponential growth__, but slower than all at once. It's
usually used 
- when first starting connection,
- when connection goes dead waiting for timeout and we go into congestion
  control.

### Congestion Control Mode

At timeout, entering _congestion control_ mode:

- set slow start threshold to `CongestionWindow/2`
- slow start until window reaches the threshold
- grow linearly after that (i.e., back to congestion avoidance)


__Question:__ How many of your packets are in the network after you receive an
ack for a retransmitted packet?

> At each point reset, the network is empty of my packets.

Bandwidth is still wasted when we are waiting for packet to timeout. Hence, we
introduce fast retransmit.

## Fast Retransmit

Basic idea: use duplicate ACKs (e.g. 3) to trigger retransmission.


How fast is *fast*? - 1RTT + 3RTT/W

After a fast retransimission, how many packets/acks are in the network? - 97

# Congestion Avoidance

TCP's strategy is invoking **controlling congestion once it happened**, and repeatedly
increase load in an effort to find the point at which congestion occurs, and
then back off.

However, there is an alternative strategy called __Congestion Avoidance__
instead of congestion _control_ so that:

- ___predict___ _when congestion is_ __about__ _to happen._
- reduce rate before packets start being discarded.

There are two possibilities in predict the congestion:

1. Host-centric (or called [Source-based Congestion
   Avoidance](#source-based-congestion-control)): TCP Vegas
1. Router-centric: DECbit (not covered) and RED Gateways.

## Source-Based Congestion Control

There are also two ways for host to predict:

- Router Feedback: inform the source it's going too fast.
- Implicit Feedback: source watches for some sign that router’s queue is
  building up and congestion will happen too.

Let `BaseRTT` be the minimum of all measured RTTs (commonly the RTT of the first
packet). Let `BaseRTT` be the minimum of all measured RTTs (commonly the RTT of the first packet)
> `ExpectRate = CongestionWindow/BaseRTT`

Source calculates sending rate, `ActualRate`, which __in principle__, should be equal to
> `ActualRate = CongestionWindow/RTT (real RTT)`

However, the source computes `ActualRate` as follow: once per RTT,

1. Sends a distinguished packet
1. Computes the RTT of this distinguished packet (when its ACK arrives)
1. Divide number of bytes transmitted while waiting for the ACK by the RTT measured.

Source then compares `ActualRate` with `ExpectRate`:

    Diff = ExpectRate - ActualRate
    if Diff < α
        increase CongestionWindow linearly
    else if Diff > β
        decrease CongestionWindow linearly
    else
        leave CongestionWindow unchanged

## Random Early Detection

RED is implemented at the routers. The notification is implicit.

- The router just drop a packet of the source.

    How to determie I'm going to congest?

    + Do we have congestion? - check link or whether packets accumulate.

    + Which packet do I drop? - Check queue to see which packet to drop is
      inefficient. Just randomly drop an incoming packet.

    + Look at the average length of queue not actual length.

- Route could make explicit notification by marking the packet.

In short, rather than wait for queue to become full, route just drop each
arriving packet with some drop probability whenever the average queue length
exceeds some drop level.

### Compute Average Queue Length

> `AvgLen = (1 – Weight) * AvgLen + Weight * SampleLen`

`SampleLen` is queue length each time a packet arrives, and 0 < `Weight` < 1
(usually 0.002).

### Compute Probability _P_

    TempP = MaxP * (AvgLen - MinThreshold) / (MaxThreshold - MinThreshold)
    P     = TempP / (1 - count * TempP)

`count` = number of __consecutive__ packets NOT dropped while within
`MinThresh` and `MaxThresh`

### Drop-Tail vs RED

- Lower RTT (makes Internet more reponsive)
- To be more fair among the flows
    <!--+ hopefully you lose only one packet per RTT (per window)-->
    <!--+ spread drops among all flows-->
    + Evenly spread loses among flows.
- Lose only one packet one RTT

So less timeout, more fast retransmits

All call Active Queue Management (AQM)
